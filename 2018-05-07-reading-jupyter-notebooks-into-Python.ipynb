{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Jupyter notebooks into Python\n",
    "\n",
    "For my [digitized notes](https://jessicastringham.net/2018/05/06/notebook-tour.html) project, I wrote a few scripts that read Markdown cells from Jupyter notebook files. Specifically, I read a notebook's non-empty Markdown cells and used them for my search index and flashcard database. Reading Jupyter notebooks as data is pretty easy! Below I'll read the non-empty markdown cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "path = '2018-05-02-HMM.ipynb'\n",
    "\n",
    "NB_VERSION = 4\n",
    "\n",
    "with open(path) as f:\n",
    "    nb = nbformat.read(f, NB_VERSION)\n",
    "\n",
    "markdown_cells = [\n",
    "    cell['source']\n",
    "    for cell in nb['cells']  # go through the cells\n",
    "    if cell['cell_type'] == 'markdown' and cell['source']  # skip things like 'code' cells, and empty markdown cells\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Markdown\n",
    "\n",
    "Below shows how to render markdown in a iPython notebook to show what I can do with a dictionary of Jupyter notebook data. This is also how I render flashcards in [digitized notes](https://jessicastringham.net/2018/05/06/notebook-tour.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Below is data loaded from [this other file](2018-05-02-HMM.ipynb)!** \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# HMM exact inference\n",
       "\n",
       "This demo shows exact inference on a HMM with known, discrete transition and emission distributions that are fixed over time. It does alpha recursion, which is a sum-product algorithm on HMMs.\n",
       "\n",
       "The problem is taken from Example 23.3 from [\"Bayesian Reasoning and Machine Learning\"](http://www.cs.ucl.ac.uk/staff/d.barber/brml/), and this is more or less a port of the provided Matlab implementation with my commentary.\n",
       "\n",
       "I'm trying to understand how my probabilistic graphical modelling class can be represented in code, so I try to go through this painfully slow and show how the `numpy` arrays map to the discrete probability distributions.\n",
       "\n",
       "## Problem\n",
       "\n",
       "The idea is that there's someone moving around a room. You can't see them, but you can hear bumps and creaks from them moving around. You know the probability of someone bumping or creaking at each location in the room. You also know how one moves around the room.\n",
       "Using the sequence of bumps and/or creaks, the goal is to figure out the locations in the room.\n",
       "\n",
       "### HMMs\n",
       "\n",
       "![HMM diagram](2018-05-02-hmm.png)\n",
       "\n",
       "This problem can be modeled using a Hidden Markov Model. At each timestep $t$ in the sequence, there's the visible state $v_t$ (the bump/creak combination) and the hidden state $h_t$ (the location in the room.)\n",
       "\n",
       "The goal of *filtering* is to show the probability distribution over the locations in the room at a given timestep $t$ given the bumps/creaks from the current and previous timesteps, $p(h_t\\mid v_{1:t})$. Plotting this distribution at each timestep gives a heatmap of where in the room we think the person is. \n",
       "\n",
       "In this model, there is a transition distribution $p(h_t \\mid h_{t - 1})$ to show that each hidden state depends on the previous timestep's hidden state. There also is the emission distribution $p(v_t \\mid h_t)$ to show each visible state depends on the corresponding hidden state. There's also the probability of where in the room the person starts, $p(h_1)$.\n",
       "\n",
       "The rest of the notebook shows:\n",
       " - Setting up the known distributions $p(h_1)$, $p(h_t \\mid h_{t - 1})$, and $p(v_t \\mid h_t)$. This is a lot of the notebook!\n",
       " - Generating some data for the locations ($h_{1:t}$) and sounds ($v_{1:t}$) from that distribution.\n",
       " - Finally I get to alpha recursion. I try to predict $h_{1:t}$ based on $v_{1:t}$, $p(h_1)$, $p(h_t \\mid h_{t - 1})$, and $p(v_t \\mid h_t)$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\"**Below is data loaded from [this other file]({})!** \\n\\n\".format(path)))\n",
    "display(Markdown(markdown_cells[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
